{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "ORB_SVM(85%) .ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOLKcMu6BJ/0YtE3/MeMNNm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seyinia/oluwaseyi/blob/master/ORB_SVM\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AUBPR-R4Ag7n",
        "outputId": "c259e46f-4ac7-4b3c-8f65-19dc69c10685"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9GYINeQHAeTe",
        "outputId": "31918b8c-8e84-4cef-95c6-a2cc6397499a"
      },
      "source": [
        "\n",
        "\n",
        "\"\"\"\n",
        "SIGN LANGUAGE RECOGNITION\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "\n",
        "# Get the training classes names and store them in a list\n",
        "#Here we use folder names for class names\n",
        "\n",
        "#train_path = 'dataset/train'  # Names are A, B, C, ETC\n",
        "train_path = \"/content/drive/MyDrive/Sign language dataset/Asl_alphabet_train_250\"  # Folder Names are SIGNS\n",
        "training_names = os.listdir(train_path)\n",
        "\n",
        "print (training_names)\n",
        "# Get path to all images and save them in a list\n",
        "# image_paths and the corresponding label in image_paths\n",
        "image_paths = []\n",
        "image_classes = []\n",
        "class_id = 0\n",
        "\n",
        "#To make it easy to list all file names in a directory let us define a function\n",
        "#\n",
        "def imglist(path):    \n",
        "    return [os.path.join(path, f) for f in os.listdir(path)]\n",
        "\n",
        "#Fill the placeholder empty lists with image path, classes, and add class ID number\n",
        "#\n",
        "    \n",
        "for training_name in training_names:\n",
        "    dir = os.path.join(train_path, training_name)\n",
        "    class_path = imglist(dir)\n",
        "    image_paths+=class_path\n",
        "    image_classes+=[class_id]*len(class_path)\n",
        "    class_id+=1\n",
        "\n",
        "# Create feature extraction and keypoint detector objects\n",
        "    #SIFT is not available anymore in openCV    \n",
        "# Create List where all the descriptors will be stored\n",
        "des_list = []\n",
        "\n",
        "#BRISK is a good replacement to SIFT. ORB also works but didn;t work well for this example\n",
        "#brisk = cv2.BRISK_create(30)\n",
        "\n",
        "#for image_path in image_paths:\n",
        " #   im = cv2.imread(image_path)\n",
        "  #  kpts, des = brisk.detectAndCompute(im, None)\n",
        "   # des_list.append((image_path, des))   \n",
        "    \n",
        "    \n",
        "\n",
        "#orb = cv2.ORB_create(edgeThreshold=10, patchSize=31, nlevels=8, fastThreshold=5, scaleFactor=1.2, WTA_K=2,scoreType=cv2.ORB_HARRIS_SCORE, firstLevel=0, nfeatures=200)  # OpenCV 3 backward incompatibility: Do not create a detector with `cv2.ORB()`.\n",
        "#orb = cv2.ORB_create(scoreType=cv2.ORB_FAST_SCORE)\n",
        "orb = cv2.ORB_create(nfeatures=100000, scoreType=cv2.ORB_FAST_SCORE)\n",
        "for image_path in image_paths:\n",
        "    im = cv2.imread(image_path, 0)\n",
        "    key_points, description = orb.detectAndCompute(im, None)\n",
        "    #x_train= cv2.drawKeypoints(im, key_points, None,flags=0) # Draw circles.\n",
        "    des_list.append((image_path, description))\n",
        "    \n",
        "# Stack all the descriptors vertically in a numpy array\n",
        "descriptors = des_list[0][1]\n",
        "for image_path, descriptor in des_list[1:]:\n",
        "    descriptors = np.vstack((descriptors, descriptor))  \n",
        "    \n",
        "\n",
        "#kmeans works only on float, so convert integers to float\n",
        "descriptors_float = descriptors.astype(float)  \n",
        "\n",
        "# Perform k-means clustering and vector quantization\n",
        "from scipy.cluster.vq import kmeans, vq\n",
        "\n",
        "k = 200  #k means with 100 clusters gives lower accuracy for the aeroplane example\n",
        "voc, variance = kmeans(descriptors_float, k, 1) \n",
        "\n",
        "# Calculate the histogram of features and represent them as vector\n",
        "#vq Assigns codes from a code book to observations.\n",
        "im_features = np.zeros((len(image_paths), k), \"float32\")\n",
        "for i in range(len(image_paths)):\n",
        "    words, distance = vq(des_list[i][1],voc)\n",
        "    for w in words:\n",
        "        im_features[i][w] += 1\n",
        "\n",
        "# Perform Tf-Idf vectorization\n",
        "nbr_occurences = np.sum( (im_features > 0) * 1, axis = 0)\n",
        "idf = np.array(np.log((1.0*len(image_paths)+1) / (1.0*nbr_occurences + 1)), 'float32')\n",
        "\n",
        "# Scaling the words\n",
        "#Standardize features by removing the mean and scaling to unit variance\n",
        "#In a way normalization\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "stdSlr = StandardScaler().fit(im_features)\n",
        "\n",
        "im_features = stdSlr.transform(im_features)\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "xtrain, xtest, ytrain, ytest = train_test_split(im_features, image_classes, test_size=0.30)\n",
        "\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "model = LinearSVC(max_iter=10000)\n",
        "model.fit(xtrain, ytrain)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import pylab as pl\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score #sreeni\n",
        "#from sklearn.externals import joblib\n",
        "\n",
        "import joblib\n",
        "joblib.dump((model, training_names, stdSlr, k, voc), \"Q\", compress=3)\n",
        "\n",
        "#model, classes_names, stdSlr, k, voc = joblib.load(\"Q\")\n",
        "\n",
        "\n",
        "accuracy = model.score(xtest, ytest)\n",
        "prediction=model.predict(xtest[2])\n",
        "\n",
        "print(\"accuracy is: \", accuracy)\n",
        "print(\"Prediction is:\", prediction)\n",
        "\n",
        "\n",
        "accuracy = accuracy_score(true_class, predictions)\n",
        "print (\"accuracy = \", accuracy)\n",
        "\n",
        "\n",
        "#xtest[0]\n",
        "#plt.show(mysign, cmap='gray')\n",
        "\n",
        "\n",
        "#Train an algorithm to discriminate vectors corresponding to positive and negative training images\n",
        "# Train the Linear SVM\n",
        "#from sklearn.svm import LinearSVC\n",
        "#clf = LinearSVC(max_iter=10000)  #Default of 100 is not converging\n",
        "#clf.fit(im_features, np.array(image_classes))\n",
        "\n",
        "#Train Random forest to compare how it does against SVM\n",
        "#from sklearn.ensemble import RandomForestClassifier\n",
        "#clf = RandomForestClassifier(n_estimators = 136, random_state=136)\n",
        "#clf.fit(im_features, np.array(image_classes))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['D', 'E', 'A', 'B', 'C', 'J', 'I', 'F', 'G', 'H', 'N', 'L', 'T', 'S', 'O', 'M', 'K', 'P', 'R', 'Q', 'W', 'X', 'Y', 'U', 'Z', 'V']\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}